# Git Repository Analysis and Visualization Suite

This suite consists of two Python scripts:

1.  `analyze.py`: Analyzes local Git repositories to extract commit history, lines of code changes, author contributions, and other metrics. It outputs data in various formats, including CSV files.
2.  `visualize_git_data.py`: Takes the CSV files generated by `analyze.py` and produces an HTML report with interactive charts and visualizations.

## Prerequisites

* Python 3.7+
* Git installed and accessible in your system's PATH.

## Installation

1.  **Clone/Download Scripts:**
    Ensure you have `analyze.py`, `visualize_git_data.py`, and `requirements.txt` in the same project directory.

2.  **Create a Virtual Environment (Recommended):**
    Open your terminal or command prompt in the project directory and run:
    ```bash
    python -m venv venv
    ```
    Activate the virtual environment:
    * Windows: `.\venv\Scripts\activate`
    * macOS/Linux: `source venv/bin/activate`

3.  **Install Dependencies:**
    With your virtual environment activated, install the required Python libraries using the `requirements.txt` file:
    ```bash
    pip install -r requirements.txt
    ```
    This will install libraries such as `GitPython`, `pandas`, `plotly`, `Jinja2`, `kaleido`, `PyYAML`, `python-dateutil`, `tabulate`, and `tqdm`.

## Usage

The process is typically two steps:
1.  Run `analyze.py` to process your Git repositories and generate data (CSVs).
2.  Run `visualize_git_data.py` to create an HTML report from the generated CSVs.

---

### Step 1: Running `analyze.py` (Data Extraction)

This script analyzes local Git repositories.

**Basic Command:**

```bash
python analyze.py <path_to_main_folder_containing_repos> --output_dir <path_for_generated_reports_and_csvs>
```

**Key Arguments for `analyze.py`:**

* `<main_folder>`: (Required) Path to the parent directory that contains all the cloned Git repository folders you want to analyze.
* `--output_dir`: (Optional) Directory where all output files (CSVs, JSON, Markdown, console logs if redirected) will be saved. Defaults to `./local_git_analysis_reports`.
* `--formats`: (Optional) Comma-separated list of output formats. Example: `console,csv,json,md`. Defaults to `console,csv,json,md`. The `csv` format is essential for the visualization script.
* `--since_date "YYYY-MM-DD"`: (Optional) Analyze commits only *since* this date (inclusive).
* `--until_date "YYYY-MM-DD"`: (Optional) Analyze commits only *until* this date (inclusive).
* `--log_level`: (Optional) Set the logging level. Choices: `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`. Defaults to `INFO`. `DEBUG` is very verbose and useful for troubleshooting.
* `--max_workers <N>`: (Optional) Number of parallel worker threads to process repositories. Defaults to the number of CPU cores.
* `--author_alias_file <path_to_yaml_file>`: (Optional) Path to a YAML file for mapping multiple author names/emails to a canonical identity. See example format below.
* `--repo_names "repo1,repo2,another_repo"`: (Optional) Comma-separated list of specific repository folder names (within your `<main_folder>`) to analyze. If omitted, all valid Git repos in `<main_folder>` are processed.

**Example `analyze.py` Command:**

```bash
python analyze.py ./cloned_repositories --output_dir ./analysis_output --since_date "2023-01-01" --log_level INFO --formats csv,console --author_alias_file ./author_aliases.yml
```

**Author Alias File Format (`author_aliases.yml` example):**

```yaml
author_aliases:
  - name: "Jane Doe (Canonical)"
    primary_email: "jane.doe.canonical@example.com" # Optional
    aliases:
      - "jane.doe@company.com"
      - "jdoe"
      - "Jane D."
  - name: "John Smith"
    aliases:
      - "john.smith@company.com"
      - "jsmith_github"
```

This script will generate (among other files, depending on `--formats`):
* `./analysis_output/summary_all_repos_commits.csv`
* `./analysis_output/detailed_all_repos_commits.csv`

These CSVs are the input for the visualization script.

---

### Step 2: Running `visualize_git_data.py` (HTML Report Generation)

This script takes the CSV files generated by `analyze.py` and creates an HTML report. The version discussed generates a **single HTML file with embedded static PNG images** for the charts.

**Basic Command:**

```bash
python visualize_git_data.py <path_to_csv_input_directory> --output_file <path_for_html_report>
```

**Key Arguments for `visualize_git_data.py`:**

* `<csv_input_dir>`: (Required) Path to the directory where `analyze.py` saved its output, specifically where `summary_all_repos_commits.csv` and `detailed_all_repos_commits.csv` are located (e.g., `./analysis_output` from the example above).
* `--output_file`: (Optional) Full path and filename for the generated HTML report. Defaults to `./git_embedded_image_report.html` (or `git_static_report.html` depending on the version you are using).
* `--template_file <path_to_html_template>`: (Optional) Path to a custom Jinja2 HTML template file if you want to customize the report's appearance beyond the default.
* `--log_level`: (Optional) Set the logging level. Choices: `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`. Defaults to `INFO`.
* `--top_n_contributors <N>`: (Optional) Number of top contributors to display in relevant charts and tables. Defaults to 15.
* `--top_n_repos <N>`: (Optional) Number of top repositories to display in relevant overall charts. Defaults to 20.

**Example `visualize_git_data.py` Command (for embedded images version):**

```bash
python visualize_git_data.py ./analysis_output --output_file ./final_git_report_singlefile.html --log_level INFO --top_n_contributors 10
```

This will create `final_git_report_singlefile.html` in your current directory, which is a self-contained HTML file with embedded charts.

---

## Troubleshooting

* **`NameError` or `ModuleNotFoundError`:** Ensure you have activated your virtual environment (`venv`) and successfully run `pip install -r requirements.txt`.
* **No Commits Found by `analyze.py`:**
    * Verify your repository paths are correct.
    * Check if the local clones are complete (not shallow, or run `git fetch --unshallow`).
    * If using `--since_date`, ensure commits exist within that period. Try running without date filters for specific repos to test.
    * Use `--log_level DEBUG` with `analyze.py` for verbose output.
* **Charts Not Appearing or Looking Incorrect in HTML Report:**
    * Ensure `plotly` and `kaleido` were installed correctly (`kaleido` is needed for static image generation by Plotly, including base64 embedding).
    * Use `--log_level DEBUG` with `visualize_git_data.py`. Examine the debug logs for messages about data being passed to plotting functions.
    * Ensure the CSV files in your `<csv_input_dir>` are correctly formatted and contain the expected data. The `analyze.py` script has been updated to better handle commit messages (using subject lines only) for CSV integrity.
* **Permissions:** Ensure the scripts have read access to your repository folders and write access to the output directory.